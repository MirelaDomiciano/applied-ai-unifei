{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vMq_T4eNxPU"
      },
      "source": [
        "# Geração de Texto com RNN e seu Próprio Dataset\n",
        "\n",
        "Este notebook contém o código essencial do tutorial de geração de texto do TensorFlow, adaptado para que você possa usar seu próprio arquivo de texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3j54aCLNxPZ"
      },
      "source": [
        "## 1. Configuração\n",
        "\n",
        "Primeiro, importamos as bibliotecas necessárias."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ],
      "metadata": {
        "id": "CdM9_vha16tm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6IGPViihNxPd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CgdTpucNxPf"
      },
      "source": [
        "### Carregue seu próprio texto\n",
        "\n",
        "**Instrução:** Faça o upload do seu arquivo `.txt` para o ambiente do Colab e substitua `'seu_arquivo.txt'` pelo nome do seu arquivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNQlCZooNxPg",
        "outputId": "9f7bc715-a050-4ade-debe-fbd9ed14b80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do texto: 296418 caracteres\n",
            "\n",
            "--- Início do texto ---\n",
            "Alguma Poesia\n",
            "Carlos Drummond de Andrade\n",
            "\n",
            "A Mario de Andrade, meu amigo\n",
            "\n",
            "1. POEMA DE SETE FACES\n",
            "QUANDO NASCI, um anjo torto\n",
            "desses que vivem na sombra\n",
            "disse: Vai, Carlos! ser gauche na vida.\n",
            "As casas espiam os homens\n",
            "que correm atras de mulheres.\n",
            "A t\n",
            "-----------------------\n",
            "80 caracteres únicos\n"
          ]
        }
      ],
      "source": [
        "path_to_file = 'carlos_drummond.txt' # <-- SUBSTITUA AQUI\n",
        "\n",
        "# Leia o conteúdo do arquivo\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(f'Tamanho do texto: {len(text)} caracteres')\n",
        "\n",
        "# Veja os primeiros 250 caracteres do seu texto\n",
        "print(\"\\n--- Início do texto ---\")\n",
        "print(text[:250])\n",
        "print(\"-----------------------\")\n",
        "\n",
        "# Extrai o vocabulário (caracteres únicos)\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} caracteres únicos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyXuW_EaNxPg"
      },
      "source": [
        "## 2. Processamento do Texto\n",
        "\n",
        "Agora, convertemos o texto de caracteres para uma representação numérica (IDs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PFnal6HqNxPi"
      },
      "outputs": [],
      "source": [
        "# Cria a camada de mapeamento de caracteres para IDs\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "# Cria a camada para fazer o mapeamento inverso: de IDs para caracteres\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "# Função auxiliar para converter uma sequência de IDs de volta para texto\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L33iEndNxPj"
      },
      "source": [
        "## 3. Preparação dos Dados para Treinamento\n",
        "\n",
        "Criamos sequências de entrada e saída para que o modelo aprenda a prever o próximo caractere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LZozlochNxPk"
      },
      "outputs": [],
      "source": [
        "# Converte todo o texto em uma sequência de IDs\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "\n",
        "# Cria um dataset do TensorFlow a partir dos IDs\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "# Define o tamanho da sequência para o treinamento\n",
        "seq_length = 100\n",
        "\n",
        "# Cria sequências de (seq_length + 1) caracteres\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Função para dividir cada sequência em entrada (input) e alvo (target)\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC-lhuamNxPo",
        "outputId": "0d413aaf-efc2-4cbb-b659-04b93dcfc978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Parâmetros de treinamento\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Embaralha e agrupa os dados em lotes (batches)\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros do modelo\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "00pTBm2Fzsbb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bytbe7VCNxPq"
      },
      "source": [
        "## 4. Construção do Modelo RNN\n",
        "\n",
        "Definimos a arquitetura do nosso modelo usando Keras. Ele terá uma camada de Embedding, uma camada GRU (um tipo de RNN) e uma camada Densa de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "P7SrAjdcNxPr",
        "outputId": "1f3fbe9f-4b06-49d6-9696-7058c37bcdb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"my_model_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # IMPORTANTE: A camada GRU foi trocada por LSTM\n",
        "    self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    # IMPORTANTE: A chamada agora é para self.lstm\n",
        "    # A LSTM retorna 3 valores: a saída e dois estados (h e c)\n",
        "    x, state_h, state_c = self.lstm(x, initial_state=states, training=training)\n",
        "\n",
        "    # Agrupamos os estados para a próxima iteração\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "# A instanciação do modelo agora deve funcionar sem erros\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u-CyUcANxPs"
      },
      "source": [
        "## 5. Treinamento do Modelo\n",
        "\n",
        "Compilamos o modelo com uma função de perda e um otimizador, e então iniciamos o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lDVb8X6jNxPs"
      },
      "outputs": [],
      "source": [
        "# Define a função de perda\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Compila o modelo\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxv30m1vNxPt",
        "outputId": "d130b44c-d1fa-452e-dfb9-449a8637d27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Os checkpoints serão salvos com o prefixo: ./training_checkpoints/ckpt_{epoch}.weights.h5\n"
          ]
        }
      ],
      "source": [
        "# Diretório onde os checkpoints serão salvos\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# Nome dos arquivos de checkpoint (com a extensão correta)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "print(f\"Os checkpoints serão salvos com o prefixo: {checkpoint_prefix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ca8tukNxPu",
        "outputId": "8b8cfbc6-78fe-495f-aae3-77f60bd5a286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 1.6307\n",
            "Epoch 2/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 1.6023\n",
            "Epoch 3/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 1.5807\n",
            "Epoch 4/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 1.5540\n",
            "Epoch 5/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 1.5415\n",
            "Epoch 6/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 1.5206\n",
            "Epoch 7/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 1.5012\n",
            "Epoch 8/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 1.4759\n",
            "Epoch 9/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.4533\n",
            "Epoch 10/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.4384\n",
            "Epoch 11/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.4179\n",
            "Epoch 12/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.3929\n",
            "Epoch 13/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 1.3739\n",
            "Epoch 14/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.3514\n",
            "Epoch 15/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.3257\n",
            "Epoch 16/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 1.3051\n",
            "Epoch 17/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 1.2804\n",
            "Epoch 18/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 1.2544\n",
            "Epoch 19/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 1.2337\n",
            "Epoch 20/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 1.2023\n",
            "Epoch 21/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 1.1757\n",
            "Epoch 22/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 1.1478\n",
            "Epoch 23/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 1.1177\n",
            "Epoch 24/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 1.0872\n",
            "Epoch 25/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 1.0543\n",
            "Epoch 26/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 1.0302\n",
            "Epoch 27/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.9899\n",
            "Epoch 28/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.9570\n",
            "Epoch 29/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.9228\n",
            "Epoch 30/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.8861\n",
            "Epoch 31/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.8486\n",
            "Epoch 32/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.8152\n",
            "Epoch 33/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.7767\n",
            "Epoch 34/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.7401\n",
            "Epoch 35/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.7040\n",
            "Epoch 36/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.6640\n",
            "Epoch 37/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.6277\n",
            "Epoch 38/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.5905\n",
            "Epoch 39/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.5556\n",
            "Epoch 40/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.5217\n",
            "Epoch 41/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.4865\n",
            "Epoch 42/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.4580\n",
            "Epoch 43/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.4277\n",
            "Epoch 44/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.3985\n",
            "Epoch 45/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.3669\n",
            "Epoch 46/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.3416\n",
            "Epoch 47/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.3159\n",
            "Epoch 48/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.2953\n",
            "Epoch 49/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.2718\n",
            "Epoch 50/50\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.2494\n"
          ]
        }
      ],
      "source": [
        "# Define o número de épocas para o treinamento\n",
        "EPOCHS = 50\n",
        "\n",
        "# Inicia o treinamento\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfakNAIwNxPu"
      },
      "source": [
        "## 6. Geração de Texto\n",
        "\n",
        "Com o modelo treinado, agora podemos usá-lo para gerar texto. Criamos um modelo de \"um passo\" que gera um caractere de cada vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U0vfYBjINxPv"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "    return predicted_chars, states\n",
        "\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oulM97dNxPv"
      },
      "source": [
        "### Execute o loop de geração\n",
        "\n",
        "Agora, vamos gerar 1000 caracteres. Você pode (e deve!) alterar o texto inicial (`next_char`) para ver como o modelo responde a diferentes prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wzLfNhxNxPv",
        "outputId": "6845f1da-54dd-4ee8-9c2a-a1bcba2b5ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mario dos serros.\n",
            "\n",
            "o BRaVERINTA\n",
            "\n",
            "Asti, ela forta\n",
            "capri\n",
            "Nao era Mariando.\n",
            "Sou carguiz a sitir louco\n",
            "de ris, preto, virgouio palavra.\n",
            "O dia entranho (minha sentenca\n",
            "da alguem certo que me cartila\n",
            "em bordaces, melhor mulher\n",
            "Andrade pada\n",
            "\n",
            "O chao e cama sempre a cingil me silvo\n",
            "no pais desgosto dos AmOr.\n",
            "Descebo ideirava ha o outro, por\n",
            "[anto.\n",
            "A lingua grouxante?\n",
            "Estretam-se na pureza\n",
            "deste mundo enfasto,\n",
            "esbou, se vai dar noite,\n",
            "sua coxa se aflexo\n",
            "algamo irregasoava\n",
            "no sono damos o homem?\n",
            "- As outras de calma porem nada.\n",
            "O vidrileiro coqueir\n",
            "e nao agre vosso pai.\n",
            "Mas o campo e dor.\n",
            "O mundo entre nos oprimidos\n",
            "para decifros ficou de todos,\n",
            "teu companheiro corredor;\n",
            "hora que frateira\n",
            "tem luz-se e o selancolica\n",
            "nas cavernais de queixa\n",
            "com qual Nao amadeira\n",
            "minha cor de amor acordado\n",
            "que a noite era nobre\n",
            "vai devassando\n",
            "paca-los bercos,\n",
            "umas pousas.\n",
            "Nao e agora, orvalhado;\n",
            "so esperso e um vago\n",
            "esperando\n",
            "a mesa, prolquidade.\n",
            "Nao contato, na conhca\n",
            "no chao, no chao.\n",
            "Era no mur,\n",
            "em nos ou nao e nada\n",
            "e \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Tempo de execução: 2.60s\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Mario']) # <-- MUDE O TEXTO INICIAL AQUI\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000): # Gera 1000 caracteres\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print(f'\\nTempo de execução: {end - start:.2f}s')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}